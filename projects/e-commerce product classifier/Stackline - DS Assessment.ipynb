{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stackline - DS Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import Convolution2D\n",
    "import h5py\n",
    "from keras import applications\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Model\n",
    "import urllib\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_excel('Training_Data_Assessment.xlsx')\n",
    "df_test = pd.read_excel('Data To Classify_Assessment.xlsx')\n",
    "categories = pd.read_excel('Categories_Assessment.xlsx',header=None,names=['CategoryName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASIN</th>\n",
       "      <th>CategoryName</th>\n",
       "      <th>BrandName</th>\n",
       "      <th>Title</th>\n",
       "      <th>ImageUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B014FCC4NO</td>\n",
       "      <td>Headphones</td>\n",
       "      <td>01 Audio</td>\n",
       "      <td>Bluetooth Headphones, Wireless Earbuds Earphon...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/31KpP1yO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00RE20CVO</td>\n",
       "      <td>Cables</td>\n",
       "      <td>1byone</td>\n",
       "      <td>1Byone Lightning to USB Cable 3.28ft (1M) for...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/31cldYZD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00HEZV6AC</td>\n",
       "      <td>Security &amp; Surveillance</td>\n",
       "      <td>1byone</td>\n",
       "      <td>1byone? 7 Inch Colorful LCD Screen Video Doorb...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41by3Sjc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00ZWOU5R2</td>\n",
       "      <td>Streaming Media</td>\n",
       "      <td>1byone</td>\n",
       "      <td>1byone 5GHz Wireless HDMI Streaming Media Play...</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00RFLXE0A</td>\n",
       "      <td>Television Accessories</td>\n",
       "      <td>1byone</td>\n",
       "      <td>1byone Shiny Antenna Super Thin Amplified HDTV...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/314oPMta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ASIN             CategoryName BrandName  \\\n",
       "0  B014FCC4NO               Headphones  01 Audio   \n",
       "1  B00RE20CVO                   Cables    1byone   \n",
       "2  B00HEZV6AC  Security & Surveillance    1byone   \n",
       "3  B00ZWOU5R2          Streaming Media    1byone   \n",
       "4  B00RFLXE0A   Television Accessories    1byone   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Bluetooth Headphones, Wireless Earbuds Earphon...   \n",
       "1   1Byone Lightning to USB Cable 3.28ft (1M) for...   \n",
       "2  1byone? 7 Inch Colorful LCD Screen Video Doorb...   \n",
       "3  1byone 5GHz Wireless HDMI Streaming Media Play...   \n",
       "4  1byone Shiny Antenna Super Thin Amplified HDTV...   \n",
       "\n",
       "                                            ImageUrl  \n",
       "0  http://ecx.images-amazon.com/images/I/31KpP1yO...  \n",
       "1  http://ecx.images-amazon.com/images/I/31cldYZD...  \n",
       "2  http://ecx.images-amazon.com/images/I/41by3Sjc...  \n",
       "3  https://images-na.ssl-images-amazon.com/images...  \n",
       "4  http://ecx.images-amazon.com/images/I/314oPMta...  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASIN</th>\n",
       "      <th>CategoryName</th>\n",
       "      <th>BrandName</th>\n",
       "      <th>Title</th>\n",
       "      <th>ImageUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6034</td>\n",
       "      <td>6034</td>\n",
       "      <td>6034</td>\n",
       "      <td>6034</td>\n",
       "      <td>6034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>6031</td>\n",
       "      <td>63</td>\n",
       "      <td>1480</td>\n",
       "      <td>6009</td>\n",
       "      <td>5774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>B019ZY1ZWS</td>\n",
       "      <td>Keyboards</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>Quze Adjustable Wooden Laptop Desk Notebook Co...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41KHRFUc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>155</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ASIN CategoryName BrandName  \\\n",
       "count         6034         6034      6034   \n",
       "unique        6031           63      1480   \n",
       "top     B019ZY1ZWS    Keyboards   Samsung   \n",
       "freq             2          100       155   \n",
       "\n",
       "                                                    Title  \\\n",
       "count                                                6034   \n",
       "unique                                               6009   \n",
       "top     Quze Adjustable Wooden Laptop Desk Notebook Co...   \n",
       "freq                                                    3   \n",
       "\n",
       "                                                 ImageUrl  \n",
       "count                                                6034  \n",
       "unique                                               5774  \n",
       "top     http://ecx.images-amazon.com/images/I/41KHRFUc...  \n",
       "freq                                                   22  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASIN</th>\n",
       "      <th>BrandName</th>\n",
       "      <th>Title</th>\n",
       "      <th>ImageUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B005DIRI6I</td>\n",
       "      <td>Portta</td>\n",
       "      <td>Portta Digital Coaxial Toslink to Analog (L/R)...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/01KGAAk9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000OYR9S8</td>\n",
       "      <td>Savage</td>\n",
       "      <td>Savage SV-107X12-56 Seamless Background Paper ...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/01OWR5or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00WT9UV3Q</td>\n",
       "      <td>Avtech</td>\n",
       "      <td>AVTech AVS228 8CH HD-SDI DVR</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/11%2BWuk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B010F69FRC</td>\n",
       "      <td>Dahua</td>\n",
       "      <td>Dahua NVR4416-P / EX-NVRDR-P Dual Core CPU - 1...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/111McGzd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00U4S0FE4</td>\n",
       "      <td>HP</td>\n",
       "      <td>HP KVM Console G3 Switch 0x1x8 - 8 Ports - USB...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/112CVCFg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ASIN BrandName                                              Title  \\\n",
       "0  B005DIRI6I    Portta  Portta Digital Coaxial Toslink to Analog (L/R)...   \n",
       "1  B000OYR9S8    Savage  Savage SV-107X12-56 Seamless Background Paper ...   \n",
       "2  B00WT9UV3Q    Avtech                       AVTech AVS228 8CH HD-SDI DVR   \n",
       "3  B010F69FRC     Dahua  Dahua NVR4416-P / EX-NVRDR-P Dual Core CPU - 1...   \n",
       "4  B00U4S0FE4        HP  HP KVM Console G3 Switch 0x1x8 - 8 Ports - USB...   \n",
       "\n",
       "                                            ImageUrl  \n",
       "0  http://ecx.images-amazon.com/images/I/01KGAAk9...  \n",
       "1  http://ecx.images-amazon.com/images/I/01OWR5or...  \n",
       "2  http://ecx.images-amazon.com/images/I/11%2BWuk...  \n",
       "3  http://ecx.images-amazon.com/images/I/111McGzd...  \n",
       "4  http://ecx.images-amazon.com/images/I/112CVCFg...  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASIN</th>\n",
       "      <th>BrandName</th>\n",
       "      <th>Title</th>\n",
       "      <th>ImageUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>57030</td>\n",
       "      <td>55911</td>\n",
       "      <td>57030</td>\n",
       "      <td>57030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>57030</td>\n",
       "      <td>6800</td>\n",
       "      <td>56564</td>\n",
       "      <td>54638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>B00I1CPACM</td>\n",
       "      <td>HP</td>\n",
       "      <td>Misfit Shine - Activity and Sleep Monitor</td>\n",
       "      <td>http://g-ecx.images-amazon.com/images/G/01/x-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1355</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ASIN BrandName                                      Title  \\\n",
       "count        57030     55911                                      57030   \n",
       "unique       57030      6800                                      56564   \n",
       "top     B00I1CPACM        HP  Misfit Shine - Activity and Sleep Monitor   \n",
       "freq             1      1355                                          9   \n",
       "\n",
       "                                                 ImageUrl  \n",
       "count                                               57030  \n",
       "unique                                              54638  \n",
       "top     http://g-ecx.images-amazon.com/images/G/01/x-s...  \n",
       "freq                                                   50  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CategoryName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Headphones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Security &amp; Surveillance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Streaming Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Television Accessories</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              CategoryName\n",
       "0               Headphones\n",
       "1                   Cables\n",
       "2  Security & Surveillance\n",
       "3          Streaming Media\n",
       "4   Television Accessories"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_categories = categories['CategoryName']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "1. Training data: 6031 unique ASIN in 6034 rows. Need to remove duplicates.\n",
    "\n",
    "2. Testing data: 57030 unique ASIN in 57030 rows. No duplicates found.\n",
    "\n",
    "3. No Null values observed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing duplicate ASINs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.drop_duplicates('ASIN',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_df_train, x_df_test, y_df_train, y_df_test = train_test_split(df_train[['Title','ImageUrl']],df_train[['CategoryName']],\n",
    "train_size=.8, stratify=df_train['CategoryName'],random_state=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Downloading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aim**\n",
    "\n",
    "* To download training, validation and testing images from image url\n",
    "* The images are stored as\n",
    "        /train\n",
    "            /category1\n",
    "                train_image1.jpg\n",
    "                train_image2.jpg\n",
    "            /category2\n",
    "                train_image1.jpg\n",
    "                train_image2.jpg\n",
    "        /validation\n",
    "            /category1\n",
    "                validation_image1.jpg\n",
    "                validation_image2.jpg\n",
    "            /category2\n",
    "                validation_image1.jpg\n",
    "                validation_image2.jpg\n",
    "        /test\n",
    "            /New folder\n",
    "                test_image1.jpg\n",
    "                test_image2.jpg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "train_path = os.path.join(current_path,'train')\n",
    "validation_path = os.path.join(current_path,'validation')\n",
    "test_path = os.path.join(current_path,'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to download test and validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_download(x_df,y_df,unique_categories,path,category_column='CategoryName',imageurl_column='ImageUrl'):\n",
    "    for i in x_df.index:\n",
    "        for j in unique_categories:            \n",
    "            if y_df[category_column][i] == j:\n",
    "                class_path = os.path.join(path,j)\n",
    "                if not os.path.exists(class_path):\n",
    "                    os.makedirs(class_path)\n",
    "                filename = '%s.jpg'%i\n",
    "                fullfilename = os.path.join(class_path,filename)\n",
    "                if not os.path.exists(fullfilename):\n",
    "                    try:\n",
    "                        urllib.request.urlretrieve(x_df[imageurl_column][i],fullfilename)\n",
    "                    except:\n",
    "                        print('Did not download:')\n",
    "                        print(i)\n",
    "                        print(x_df[imageurl_column][i])\n",
    "                        pass\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_download(x_df=x_df_train,y_df=y_df_train,unique_categories=unique_categories,path=train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Validation Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_download(x_df=x_df_test,y_df=y_df_test,unique_categories=unique_categories,path=validation_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in df_test.index:\n",
    "    class_path = os.path.join(test_path,'New folder')\n",
    "    if not os.path.exists(class_path):\n",
    "        os.makedirs(class_path)\n",
    "    filename = '%s.jpg'%i\n",
    "    fullfilename = os.path.join(class_path,filename)\n",
    "    if not os.path.exists(fullfilename):\n",
    "        try:\n",
    "            urllib.request.urlretrieve(df_test['ImageUrl'][i],fullfilename)\n",
    "        except:\n",
    "            print('Did not download:')\n",
    "            print(i)\n",
    "            print(df_test['ImageUrl'][i])\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aim**\n",
    "\n",
    "* To build a pipeline for text features\n",
    "* To build classifiers for the text features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps in pipeline**\n",
    "\n",
    "* Convert to lowercase\n",
    "* Remove stop words\n",
    "* Convert a collection of text documents to a matrix of token counts\n",
    "* Transform a count matrix to a normalized tf or tf-idf representation. Tf means term-frequency while tf-idf means term-frequency times inverse document-frequency. This is a common term weighting scheme in information retrieval, that has also found good use in document classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classifiers used**\n",
    "\n",
    "* Multinomial Naive Bayes\n",
    "* Linear SVM with SGD\n",
    "* Random Forests\n",
    "* Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84672742336371165"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_multinomial_nb = Pipeline([('vect', CountVectorizer(stop_words='english',lowercase=True)),('tfidf', TfidfTransformer()),('clf', MultinomialNB())])\n",
    "text_clf_multinomial_nb.fit(x_df_train['Title'], y_df_train['CategoryName'])\n",
    "text_clf_multinomial_nb.score(x_df_test['Title'],y_df_test['CategoryName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90306545153272577"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_sgd = Pipeline([('vect', CountVectorizer(stop_words='english',lowercase=True)),('tfidf', TfidfTransformer()),('clf', SGDClassifier())])\n",
    "text_clf_sgd.fit(x_df_train['Title'], y_df_train['CategoryName'])\n",
    "text_clf_sgd.score(x_df_test['Title'],y_df_test['CategoryName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84424192212096105"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_rf = Pipeline([('vect', CountVectorizer(stop_words='english',lowercase=True)),('tfidf', TfidfTransformer()),('clf', RandomForestClassifier())])\n",
    "text_clf_rf.fit(x_df_train['Title'], y_df_train['CategoryName'])\n",
    "text_clf_rf.score(x_df_test['Title'],y_df_test['CategoryName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87903893951946976"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_logis = Pipeline([('vect', CountVectorizer(stop_words='english',lowercase=True)),('tfidf', TfidfTransformer()),('clf', LogisticRegression())])\n",
    "text_clf_logis.fit(x_df_train['Title'], y_df_train['CategoryName'])\n",
    "text_clf_logis.score(x_df_test['Title'],y_df_test['CategoryName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "* Due to time and computational constraints, I am not going be doing a grid search cross validation for the above models. \n",
    "* I believe that a test dataset accuracy of above 80% is sufficient enough as I am going to take the average of all classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aim**\n",
    "\n",
    "* To train a classifier over a pre-trained VGG16 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "top_model_weights_path = 'bottleneck_fc_model1.h5'\n",
    "train_data_dir = 'train'\n",
    "validation_data_dir = 'validation'\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building VGG16 network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = applications.VGG16(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running VGG16 is expensive, as working on CPU. I want to only do it only once. This prevents me from using data augmentation which can improve my model by preventing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Training Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4824 images belonging to 63 classes.\n"
     ]
    }
   ],
   "source": [
    "#train generator\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode= 'categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "#train variables\n",
    "nb_train_samples = len(train_generator.filenames)\n",
    "num_classes = len(train_generator.class_indices)\n",
    "predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
    "\n",
    "#creaing training feature set\n",
    "bottleneck_features_train = model.predict_generator(\n",
    "    train_generator, predict_size_train)\n",
    "np.save('bottleneck_features_train',bottleneck_features_train)\n",
    "\n",
    "#train labels\n",
    "train_labels = train_generator.classes\n",
    "train_labels = to_categorical(train_labels,63)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Validation Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1207 images belonging to 63 classes.\n"
     ]
    }
   ],
   "source": [
    "#validation generator\n",
    "generator = datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode= 'categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "#test variables\n",
    "nb_validation_samples = len(generator.filenames)\n",
    "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))\n",
    "\n",
    "#creaing validation feature set\n",
    "bottleneck_features_validation = model.predict_generator(\n",
    "    generator, predict_size_validation)\n",
    "np.save('bottleneck_features_validation',bottleneck_features_validation)\n",
    "\n",
    "#test labels\n",
    "validation_labels = generator.classes\n",
    "validation_labels = to_categorical(validation_labels,63)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Training and Validation feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading training and validation feature set generated above\n",
    "train_data = np.load('bottleneck_features_train.npy')\n",
    "validation_data = np.load('bottleneck_features_validation.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training top classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "rmsprop = optimizers.RMSprop(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4824 samples, validate on 1207 samples\n",
      "Epoch 1/30\n",
      "4824/4824 [==============================] - 8s - loss: 3.9984 - acc: 0.0800 - val_loss: 3.3763 - val_acc: 0.2038\n",
      "Epoch 2/30\n",
      "4824/4824 [==============================] - 8s - loss: 3.3413 - acc: 0.2075 - val_loss: 2.7534 - val_acc: 0.3538\n",
      "Epoch 3/30\n",
      "4824/4824 [==============================] - 9s - loss: 2.9185 - acc: 0.2942 - val_loss: 2.4531 - val_acc: 0.4300\n",
      "Epoch 4/30\n",
      "4824/4824 [==============================] - 8s - loss: 2.6710 - acc: 0.3472 - val_loss: 2.3308 - val_acc: 0.4457\n",
      "Epoch 5/30\n",
      "4824/4824 [==============================] - 9s - loss: 2.4280 - acc: 0.3899 - val_loss: 2.2168 - val_acc: 0.4847\n",
      "Epoch 6/30\n",
      "4824/4824 [==============================] - 9s - loss: 2.2637 - acc: 0.4274 - val_loss: 2.1571 - val_acc: 0.4963\n",
      "Epoch 7/30\n",
      "4824/4824 [==============================] - 8s - loss: 2.1048 - acc: 0.4600 - val_loss: 2.0917 - val_acc: 0.4954\n",
      "Epoch 8/30\n",
      "4824/4824 [==============================] - 9s - loss: 1.9780 - acc: 0.4859 - val_loss: 2.0977 - val_acc: 0.5162\n",
      "Epoch 9/30\n",
      "4824/4824 [==============================] - 9s - loss: 1.8645 - acc: 0.5122 - val_loss: 2.0625 - val_acc: 0.5153\n",
      "Epoch 10/30\n",
      "4824/4824 [==============================] - 9s - loss: 1.7603 - acc: 0.5359 - val_loss: 2.1132 - val_acc: 0.4954\n",
      "Epoch 11/30\n",
      "4824/4824 [==============================] - 9s - loss: 1.6555 - acc: 0.5587 - val_loss: 2.1109 - val_acc: 0.5253\n",
      "Epoch 12/30\n",
      "4824/4824 [==============================] - 9s - loss: 1.5850 - acc: 0.5775 - val_loss: 2.0318 - val_acc: 0.5435\n",
      "Epoch 13/30\n",
      "4824/4824 [==============================] - 9s - loss: 1.5085 - acc: 0.5939 - val_loss: 2.0864 - val_acc: 0.5427\n",
      "Epoch 14/30\n",
      "4824/4824 [==============================] - 8s - loss: 1.4571 - acc: 0.6088 - val_loss: 2.0803 - val_acc: 0.5418\n",
      "Epoch 15/30\n",
      "4824/4824 [==============================] - 8s - loss: 1.4101 - acc: 0.6105 - val_loss: 2.1336 - val_acc: 0.5352\n",
      "Epoch 16/30\n",
      "4824/4824 [==============================] - 9s - loss: 1.3000 - acc: 0.6443 - val_loss: 2.1669 - val_acc: 0.5394\n",
      "Epoch 17/30\n",
      "4824/4824 [==============================] - 9s - loss: 1.2776 - acc: 0.6453 - val_loss: 2.2246 - val_acc: 0.5476\n",
      "Epoch 18/30\n",
      "4824/4824 [==============================] - 9s - loss: 1.2362 - acc: 0.6495 - val_loss: 2.1964 - val_acc: 0.5452\n",
      "Epoch 19/30\n",
      "4824/4824 [==============================] - 8s - loss: 1.1842 - acc: 0.6714 - val_loss: 2.2252 - val_acc: 0.5418\n",
      "Epoch 20/30\n",
      "4824/4824 [==============================] - 8s - loss: 1.1389 - acc: 0.6833 - val_loss: 2.4549 - val_acc: 0.5327\n",
      "Epoch 21/30\n",
      "4824/4824 [==============================] - 8s - loss: 1.1124 - acc: 0.6886 - val_loss: 2.3444 - val_acc: 0.5551\n",
      "Epoch 22/30\n",
      "4824/4824 [==============================] - 8s - loss: 1.0568 - acc: 0.7009 - val_loss: 2.3186 - val_acc: 0.5468\n",
      "Epoch 23/30\n",
      "4824/4824 [==============================] - 9s - loss: 1.0688 - acc: 0.7071 - val_loss: 2.4758 - val_acc: 0.5418\n",
      "Epoch 24/30\n",
      "4824/4824 [==============================] - 9s - loss: 1.0483 - acc: 0.7013 - val_loss: 2.4577 - val_acc: 0.5534\n",
      "Epoch 25/30\n",
      "4824/4824 [==============================] - 8s - loss: 1.0009 - acc: 0.7131 - val_loss: 2.5250 - val_acc: 0.5493\n",
      "Epoch 26/30\n",
      "4824/4824 [==============================] - 8s - loss: 0.9918 - acc: 0.7224 - val_loss: 2.3880 - val_acc: 0.5626\n",
      "Epoch 27/30\n",
      "4824/4824 [==============================] - 8s - loss: 0.9083 - acc: 0.7367 - val_loss: 2.3581 - val_acc: 0.5559\n",
      "Epoch 28/30\n",
      "4824/4824 [==============================] - 8s - loss: 0.9281 - acc: 0.7396 - val_loss: 2.6533 - val_acc: 0.5576\n",
      "Epoch 29/30\n",
      "4824/4824 [==============================] - 8s - loss: 0.8948 - acc: 0.7508 - val_loss: 2.5810 - val_acc: 0.5526\n",
      "Epoch 30/30\n",
      "4824/4824 [==============================] - 8s - loss: 0.8951 - acc: 0.7531 - val_loss: 2.6397 - val_acc: 0.5708\n"
     ]
    }
   ],
   "source": [
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.6))\n",
    "top_model.add(Dense(63, activation='softmax'))\n",
    "\n",
    "top_model.compile(optimizer=rmsprop,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "top_model.fit(train_data, train_labels,\n",
    "        epochs=30,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(validation_data, validation_labels))\n",
    "top_model.save_weights(top_model_weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Final Image Recognition Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_vgg = applications.VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model_vgg.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.6))\n",
    "top_model.add(Dense(63, activation='softmax'))\n",
    "\n",
    "top_model.load_weights('bottleneck_fc_model1.h5')\n",
    "\n",
    "model = Model(inputs = model_vgg.input, outputs = top_model(model_vgg.output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Category based on Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.reset_index(inplace=True)\n",
    "filename=[]\n",
    "vgg16_predictions=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2100 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "final_data_dir='test'\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        final_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        class_mode=None,\n",
    "        batch_size=1)\n",
    "\n",
    "filenames = test_generator.filenames\n",
    "nb_samples = len(filenames)\n",
    "\n",
    "predict = model.predict_generator(test_generator,steps = nb_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make image classification results into a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for f in filenames:\n",
    "    filename.append(f)\n",
    "for r in predict:\n",
    "    vgg16_predictions.append(np.argmax(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57030"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_res = pd.DataFrame(\n",
    "    {'filename': [f[11:-4] for f in filename],\n",
    "     'category': vgg16_predictions,\n",
    "    })\n",
    "ir_res.to_csv('ir_res.csv')\n",
    "len(ir_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Product Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting category name from index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=pd.read_csv('ir_res.csv')\n",
    "index=train_generator.class_indices\n",
    "y=list(x['category'])\n",
    "categories_p=[]\n",
    "for i in y:\n",
    "    for j in index:\n",
    "        if i == index[j]:\n",
    "            categories_p.append(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collecting all predictions from all classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.set_index('ASIN',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=text_clf_multinomial_nb.predict(df_test['Title'])\n",
    "b=text_clf_sgd.predict(df_test['Title'])\n",
    "c=text_clf_rf.predict(df_test['Title'])\n",
    "d=text_clf_logis.predict(df_test['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ir_res_new = pd.DataFrame(\n",
    "    {'ASIN': x['filename'],\n",
    "     'CNN Category': categories_p,\n",
    "    })\n",
    "ir_res_new.set_index('ASIN',inplace=True)\n",
    "\n",
    "predictions = df_test.join(ir_res_new)\n",
    "predictions.drop(['Title','ImageUrl','BrandName'],1, inplace=True)\n",
    "predictions['Multinomial NB Category'] = a\n",
    "predictions['SVC Category'] = b\n",
    "predictions['RF Category'] = c\n",
    "predictions['LogisticR Category'] = d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take Average of all 5 classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_pred =[]\n",
    "for i in range(len(df_test)):\n",
    "    lst = [a[i],b[i],c[i],d[i],predictions['CNN Category'][i]]\n",
    "    final_pred.append(max(set(lst), key=lst.count))\n",
    "df_test['Category'] = final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.to_csv('final_prediction.csv')\n",
    "predictions.to_csv('predictions_allClassifiers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to time and computational constraints, I was not able to improve upon my model. Some methods by which we can get a robust model is given below:\n",
    "\n",
    "**Image Classification**\n",
    "\n",
    "*  Fine tuning of the last convolutional block of VGG16 alongwith my top classifier could improve validation accuracy\n",
    "* Running VGG only once for training prevents me from using data augmentation. Looking for ways to use data augmentation can really help\n",
    "* More training data. We have approximately 60 samples per category. In my opinion, more training data will lead to better image categorization\n",
    "* Use more aggressive dropout\n",
    "* Use of L1 and L2 regularization (also known as \"weight decay\")\n",
    "\n",
    "**Text Classification**\n",
    "* Grid Search CV of classifiers\n",
    "* Use text preprocessing steps including stemming, lemmatization, and object standardization\n",
    "* Compare with other classifiers available on scikit-learn\n",
    "\n",
    "**Combined Classifier**\n",
    "\n",
    "For the final model, I can create a neural network that has a convolutional branch one on side while the other branch processes vectorized words: One part of the model uses a convolutional neural network to process the images, while the other processes the bag-of-words text. The two are combined for the final classification. The VGG convolutional network provides the computer vision processing of the images, while simple fully-connected neural networks process the text. The last layer of neurons is simply the combination from both parts of the model, and is used to produce the final classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.dataweave.com/implementing-a-machine-learning-based-ecommerce-product-classification-system-f846d894148b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.insightdatascience.com/classifying-e-commerce-products-based-on-images-and-text-14b3f98f899e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://cbonnett.github.io/Insight.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://techblog.commercetools.com/boosting-product-categorization-with-machine-learning-ad4dbd30b0e8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://cs229.stanford.edu/proj2011/LinShankar-Applying%20Machine%20Learning%20to%20Product%20Categorization.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/georgetown-analytics/product-classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2017/01/ultimate-guide-to-understand-implement-natural-language-processing-codes-in-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
